# Deep Learning Using Pytorch

1. [Math](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%201%20-%20Math)
2. [Gradient Descent](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%202%20-%20Gradient%20Descent)
3. [ANN](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%203%20-%20ANN)
    1. Regression model
    2. Binary Classification Model
    3. Multiclass Classification Model
    4. Vary the Learning Rate
    5. Depth vs Width Model
5. [Overfitting & CrossValidation](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%204%20-%20Overfitting%20%26%20CrossValidation)
    1. Overfitting and Underfitting
    2.  Cross Validation
    3.  Data Loader (`torch.utils.data.DataLoader` & `torch.utils.data.TensorDataset`)
7. [Regularization](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%205%20-%20Regularization)
    1. Dropout Layers
    2. L1/L2 Regularization
    3. Batch training, Data augmentation 
9. [Metaparameters (Activations, Optimizers)](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%206%20-%20Metaparameters%20(Activations%2C%20Optimizers))
    1. Data Normalization
        1. Z-Score
        2. MinMax Scaling
    2. Batch Normalization
    3. Activation Functions
        1. Sigmoid
        2. Hiperbolic Tangent
        3. Relu/Leaky Relu/Renu-N
    4. Loss Functions
        1. MSE
        2. Binary Cross Entropy
        3. Multiclass Cross Entropy
    5. Optimizers
        1. SGD
        2. SGD With Momemtum
        2. Adam
        3. RMSProp
        4. Learning Rate Decay (`torch.optim.lr_scheduler.STepLR(optimizer, step_size=batch_size * len(train_loader), gamma=.5)`)
10. [FFN](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%207%20-%20FFN)
11. [Data](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%208%20-%20Data)
12. [Measure Model Performance](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%209%20-%20Measure%20Model%20Performance)
13. [FFN Milestone Project](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2010%20-%20FFN%20Milestone%20Project)
14. [Weights](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2011%20-%20Weights)
    1. Kaiming Weight Initialization
    2. Xavier Weight Initialization
15. [Autoencoders](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2012%20-%20Autoencoders)
16. [GPU](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2013%20-%20GPU)
17. [Convolution](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2014%20-%20Convolution)
    1. Convolution/Kernel/Feature Maps
    2. Transpose convolution
    3. Stride & Padding
    4. Average & Max pooling
18. [CNN](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2015%20-%20CNN)
19. [CNN Milestone Projects](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2016%20-%20CNN%20Milestone%20Projects)
20. [Transfer Learning](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning)
    1. Transfer Learning from own model
    2. ResNet-18 Model
    3. VGG-16 Model
    4. Pretraining with AutoEncoders
21. [Style Transfer Learning](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2018%20-%20Style%20Transfer)
22. [GANs](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2019%20-%20GANs)
23. [RNN](https://github.com/Sayan-Roy-729/Data-Science/tree/main/Deep%20Learning/Using%20Pytorch/Part%2020%20-%20RNN)
24. [Python Basics]()



## Metaparameters of a Neural Network:
1. Number of layers
2. Number of nodes in each layers
3. Learning rate
    1. Set Different Learning Rate
    2. Change the learning rates wile training
4. Data Normalization
    1. Z-Score
    2. MinMax Scaling
5. Batch Normalization
6. L1/L2 Regularization
7. Batch/MiniBatch the Data (DataLoader)
8. DropOut Layer
9. Activation functions
    1. Sigmoid
    2. Hiperbolic Tangent
    3. Relu/Leaky Relu/Renu-N
10. Optimizers
    1. SGD
    2. SGD with momentum
    3. Adam
    4. RMSProp
11. Weights
    1. Kaiming Weight Initialization
    2. Xavier Weight Initialization
12. Cross Validation



**For dynamic result or progress bar, see this [notebook](https://colab.research.google.com/drive/1F69KQN0GQZwFmiwNY0MCVA_4BzgTXXWM#scrollTo=XpGm9xdQ27Ob)**