{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc016de",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## What, why and when?\n",
    "\n",
    "![What is Transfer Learning](./images/image-1.png)\n",
    "![What is Transfer Learning](./images/image-2.png)\n",
    "\n",
    ">**When Transfer Learning is not useful**\n",
    "![What is Transfer Learning](./images/image-3.png)\n",
    "\n",
    ">**Why is transfer learning useful?**\n",
    "- Transfer learning allows you to\n",
    "    - leverage HUGE datasets and existing (source) models to solve new problems.\n",
    "    - fine-tune existing trained models to your unique data.\n",
    "    - deploy models quickly and with limited computational and data resources.\n",
    "    - \"stand on the shoulders of giants\"\n",
    "    \n",
    ">**When is transfer learning appropriate?**\n",
    "- Use transfer learning when\n",
    "    - Your problem is similar to a problem that someone else has solved (and published their model).\n",
    "    - the model was trained on a lot more data than what you have.\n",
    "    - the model is deep; shallow models are less likely to transfer well unless the target data are very similar.\n",
    "    \n",
    ">**Is transfer learning appropriate here?**\n",
    "- Fine-tune AlexNet to distinguish different models of BMWs. → ✓\n",
    "- Fine-tune AlexNet to predict credit card fraud. → ✖\n",
    "- Train a model on US housing sales data and then fine-tune that model to Zimbabwe housing sales data. → ?\n",
    "\n",
    ">**How to use transfer learning**\n",
    "- Decide whether it is appropriate: (1) Do you have insufficient complex data and (2) does a well-trained model exist?\n",
    "- Decide which (if any) layers to freeze: The closer your data to the source model.\n",
    "- Fine-tune the target model as much as possible.\n",
    "- Inspect the model and results carefully; never assume that transfer will be successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb683b1",
   "metadata": {},
   "source": [
    ">**Code:**\n",
    "- [Part 1 - MNIST to FMNIST (One Batch Tuning)](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning/Part%201%20-%20MNIST%20to%20FMNIST.ipynb)\n",
    "- [Part 2 - CodeChallenge letters to numbers (Freeze the model and only tune last output nodes)](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning/Part%202%20-%20CodeChallenge%20letters%20to%20numbers.ipynb)\n",
    "\n",
    "## Famous CNN architectures\n",
    "\n",
    "### LeNet\n",
    "\n",
    "![LeNet Model Architecture](https://d2l.ai/_images/lenet.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55818c90",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "![AlexNet Model Architecture](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-22_at_6.35.45_PM.png)\n",
    "\n",
    "![LeNet vs AlexNet](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/1200px-Comparison_image_neural_networks.svg.png)\n",
    "\n",
    "### VGGNet\n",
    "\n",
    "![VGGNet Model Architecture](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/VGG_structure.jpg/700px-VGG_structure.jpg)\n",
    "\n",
    "![VGG16 Model Architecture](https://neurohive.io/wp-content/uploads/2018/11/vgg16.png)\n",
    "\n",
    "![Different VGGNet](https://media.geeksforgeeks.org/wp-content/uploads/20200217112031/VGG16conf.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243d48b",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "![ResNet Model Architecture](https://miro.medium.com/max/1232/0*Si4ckM1MrkUxTaDH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cf54f",
   "metadata": {},
   "source": [
    "![ResNet Architecture](https://neurohive.io/wp-content/uploads/2019/01/resnet-architectures-34-101.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65347a4",
   "metadata": {},
   "source": [
    ">**Code:**\n",
    "- [Part 3 - Transfer learning with ResNet18](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning/Part%203%20-%20Transfer%20learning%20with%20ResNet18.ipynb)\n",
    "- [Part 4 - CodeChallenge VGG-16](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning/Part%204%20-%20CodeChallenge%20VGG-16.ipynb)\n",
    "\n",
    "## Pretraining with autoencoders\n",
    "\n",
    "![autoencoder with transfer tearning](./images/image-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde89a9a",
   "metadata": {},
   "source": [
    ">**How to pretrain using autoencoders:**\n",
    "1. Build an autoencoder for your data.\n",
    "2. Train the autoencoder to satisfactory performance.\n",
    "3. Create a new model that has the same architecture as the encoder, and copy the weights from the autoencoders.\n",
    "4. Add linear layers to the end of the new model.\n",
    "5. Train the transferred model to classify the data.\n",
    "\n",
    ">**Pros & cons of autoencoder pretraining**\n",
    "- Optimize the model for your data (as opposed to using an existing model, e.g., AlexNet)\n",
    "- Useful with limited data (can re-use data without overfitting)\n",
    "- Can save computation time if using an existing model.\n",
    "- Autoencoders do not necessarily identify the features that are relevant for classification. Not every learned parameter transfers.\n",
    "\n",
    ">**Code:**\n",
    "- [Part 5 - Pretraining with autoencoders](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning/Part%205%20-%20Pretraining%20with%20autoencoders.ipynb)\n",
    "- [Part 6 - CIFAR10 with autoencoder-pretrained model](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2017%20-%20Transfer%20Learning/Part%206%20-%20CIFAR10%20with%20autoencoder-pretrained%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f454b-75cd-4ea0-8a2a-2085d42334c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
