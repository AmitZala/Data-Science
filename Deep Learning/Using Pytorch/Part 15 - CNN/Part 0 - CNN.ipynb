{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83816f9",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "## The caninical CNN architecture\n",
    "\n",
    ">**Three types of layers in a CNN**\n",
    "\n",
    "| Type | Purpose |\n",
    "| :--: | :-- |\n",
    "| Convolution | Learn filters (kernels) to create feature maps |\n",
    "| Pooling | Reduce dimensionality and increase receptive field size |\n",
    "| Fully connected | Prediction (categorical and/or continuous) |\n",
    "\n",
    "![CNN Architeture](https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2020/11/1-cnnlayer.png?resize=1024%2C259&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4730a3",
   "metadata": {},
   "source": [
    ">**With increasing depth:**\n",
    "- Image resolution (number of pixels) decreases\n",
    "- Representation resolution (number of filters) increases\n",
    "- Layers are smaller but wider\n",
    "\n",
    "## CNN to classify MNIST digits\n",
    "\n",
    "![MNIST Our Architecture](./images/image-1.png)\n",
    "\n",
    ">**Code:**\n",
    "- Part 1 - CNN to classify MNIST digits\n",
    "- Part 2 - Shifted MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76adb96d",
   "metadata": {},
   "source": [
    "## Classify Gaussian Blurs\n",
    "\n",
    "![2D Gaussians](./images/image-2.png)\n",
    "\n",
    "![Architecture](./images/image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7c5c9",
   "metadata": {},
   "source": [
    ">**Code:**\n",
    "- Part 3 - Classify Gaussian blurs\n",
    "\n",
    ">**Discussion:**\n",
    "- The weights (convolution kernels) change during learning but are fixed after learning. They are independent of the data.\n",
    "- The activation of the layers in each channel (feature maps) are not learned; they are representations of the data. They can look completely different for different images, although the weights are identical.\n",
    "\n",
    ">**Code:**\n",
    "- Part 4 - Examine feature map activations\n",
    "\n",
    ">**Discussion:**\n",
    "- Reminder 1: Weights are fixed; feature layer activations require data.\n",
    "- Reminder 2: Convolution layers learn features but don't make decisions; fully-connected layers use those features to make decisions.\n",
    "- Feature map activations can (should!) be qualitatively and quantitatively inspected. Empty or near-identical maps indicate gratuitous complexity.\n",
    "- Simple models are \"easy\" to inspect; larger models become increasingly difficult. Develop the habit of thinking critically about model architecture.\n",
    "\n",
    ">**Code:**\n",
    "- Part 5 - CodeChallenge Softcoding\n",
    "- Part 6 - CodeChallenge How width the Linear Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927b9f3",
   "metadata": {},
   "source": [
    "## Do autoencoders clean Gaussians?\n",
    "\n",
    "![Autoencoder and CNN Architecture](./images/image-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d2095",
   "metadata": {},
   "source": [
    ">**Code:**\n",
    "- Part 7 - Do autoencoders clean Gaussians\n",
    "- Part 8 - CodeChallenge Autoencoders and occluded Gaussians\n",
    "- Part 9 - CodeChallenge Custom loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fd362",
   "metadata": {},
   "source": [
    "## Discover Gaussian Parameters\n",
    "\n",
    "![DL vs Statistics](./images/image-6.png)\n",
    "![DL vs Statistics](./images/image-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7bcb0",
   "metadata": {},
   "source": [
    ">**Code:**\n",
    "- Part 10 - Find the Gaussian Parameters\n",
    "- Part 11 - The EMNIST dataset (letter recognition)\n",
    "\n",
    "## Dropout in CNN\n",
    "- Dropout means that units learn to be independent of each other.\n",
    "- But dependence is the entire purpose of the kernel weights in a convolutional layer!\n",
    "- Thus, strong dropout (p=0.5) in convolutional layers might prevent learning spatial dependencies.\n",
    "- Some dropout (p=0.1 to 0.2) regularizes by adding noise.\n",
    "\n",
    "![Dropout in CNN](./images/image-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb66439",
   "metadata": {},
   "source": [
    ">**Code:**\n",
    "- Part 12 - codeChallengeBeatThis\n",
    "- Part 13 - CodeChallenge Varying number of channels\n",
    "\n",
    ">**How to choose best CNN model?**\n",
    "- There are so many options for architecture and metaparameters.\n",
    "- It is literally impossible to evaluate even a reasonably complete set of possible models.\n",
    "- Some architectures might be good for some datasets and bad for others.\n",
    "- You can never be 100% confident that any given model (yours or anyone else's) is the best.\n",
    "- There is no solution :(\n",
    "- Start from existing models, published or github, kaggle, blogs etc. Try to find models that are similar to what you need.\n",
    "- Use transfer learning.\n",
    "- Experiment, tweak, guess... be creative and think big.\n",
    "- Write down the changes and performances!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
