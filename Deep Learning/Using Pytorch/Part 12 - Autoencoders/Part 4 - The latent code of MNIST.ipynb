{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Autoencoders\n",
    "### LECTURE: The latent code of MNIST\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/dudl/?couponCode=202201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.431629Z",
     "start_time": "2022-01-31T17:12:05.306351Z"
    },
    "id": "YeuAheYyhdZw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayan\\AppData\\Local\\Temp\\ipykernel_10196\\2233319632.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# NEW! for doing PCA on the model output\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.781724Z",
     "start_time": "2022-01-31T17:12:13.432627Z"
    },
    "id": "MU7rvmWuhjud"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample_data/mnist_train_small.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import dataset (comes with colab!)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_data/mnist_train_small.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# we'll use the labels for matching with the latent code\u001b[39;00m\n\u001b[0;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[:,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/mnist_train_small.csv'"
     ]
    }
   ],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('mnist_train_small.csv','rb'), delimiter=',')\n",
    "\n",
    "# we'll use the labels for matching with the latent code\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# convert to tensor\n",
    "dataT = torch.tensor( dataNorm ).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK8Opkhgp0bO"
   },
   "source": [
    "# Create the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.782690Z",
     "start_time": "2022-01-31T17:12:13.782690Z"
    },
    "id": "JK3OO3tAtZkA"
   },
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTAE():\n",
    "\n",
    "  class aenet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,150)\n",
    "      \n",
    "      ### encoder layer\n",
    "      self.enc = nn.Linear(150,15)\n",
    "\n",
    "      ### latent layer\n",
    "      self.lat = nn.Linear(15,150)\n",
    "\n",
    "      ### decoder layer\n",
    "      self.dec = nn.Linear(150,784)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      \n",
    "      # NEW! output the hidden-layer activation\n",
    "      codex = F.relu( self.enc(x) )\n",
    "      \n",
    "      x = F.relu( self.lat(codex) )\n",
    "      y = torch.sigmoid( self.dec(x) )\n",
    "      return y,codex\n",
    "  \n",
    "  # create the model instance\n",
    "  net = aenet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.MSELoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.783688Z",
     "start_time": "2022-01-31T17:12:13.783688Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voQ6mHkfmj1F",
    "outputId": "aa97d43c-f447-430c-833a-47ea316ac7f8"
   },
   "outputs": [],
   "source": [
    "# test the model with a bit of data\n",
    "net,lossfun,optimizer = createTheMNISTAE()\n",
    "\n",
    "X = dataT[:5,:]\n",
    "yHat = net(X)\n",
    "\n",
    "print('Input shape:')\n",
    "print(X.shape)\n",
    "print(' ')\n",
    "\n",
    "# yHat is now a tuple\n",
    "print(type(yHat),len(yHat))\n",
    "print(' ')\n",
    "\n",
    "print('Shape of model output:')\n",
    "print(yHat[0].shape)\n",
    "print(' ')\n",
    "\n",
    "print('Shape of encoding layer output:')\n",
    "print(yHat[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvfGQIRGp0ht"
   },
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.783688Z",
     "start_time": "2022-01-31T17:12:13.783688Z"
    },
    "id": "IblJo1NCp0kl"
   },
   "outputs": [],
   "source": [
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10000\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTAE()\n",
    "\n",
    "  # initialize losses\n",
    "  losses = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # select a random set of images\n",
    "    randomidx = np.random.choice(dataT.shape[0],size=32)\n",
    "    X = dataT[randomidx,:]\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = net(X)[0] # NEW! here we only care about the final model output\n",
    "    loss = lossfun(yHat,X)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # losses in this epoch\n",
    "    losses[epochi] = loss.item()\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return losses,net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpGm9xdQ27Ob"
   },
   "source": [
    "# Run the model and show the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.784684Z",
     "start_time": "2022-01-31T17:12:13.784684Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "l9pCC1R2p0nu",
    "outputId": "20d8c95c-f666-494a-e776-dc70aa7448bb"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "losses,net = function2trainTheModel()\n",
    "print(f'Final loss: {losses[-1]:.4f}')\n",
    "\n",
    "# visualize the losses\n",
    "plt.plot(losses,'.-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG7_3tYbp0wm"
   },
   "source": [
    "# Inspect the latent \"code\" of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.785682Z",
     "start_time": "2022-01-31T17:12:13.785682Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "qw56zhmj87WC",
    "outputId": "175a3ebd-3ac9-405e-89c3-d754a7d69b39"
   },
   "outputs": [],
   "source": [
    "# output the latent layer\n",
    "\n",
    "# push through the entire dataset\n",
    "yHat,latent = net(dataT)\n",
    "\n",
    "# print sizes\n",
    "print(yHat.shape)\n",
    "print(latent.shape)\n",
    "\n",
    "# what does it look like?\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "ax[0].hist(latent.flatten().detach(),100)\n",
    "ax[0].set_xlabel('Latent activation value')\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[0].set_title('Distribution of latent units activations')\n",
    "\n",
    "ax[1].imshow(latent.detach(),aspect='auto',vmin=0,vmax=10)\n",
    "ax[1].set_xlabel('Latent node')\n",
    "ax[1].set_ylabel('Image number')\n",
    "ax[1].set_title('All latent activations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.786680Z",
     "start_time": "2022-01-31T17:12:13.786680Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "9SnUUHPm7xQE",
    "outputId": "9d27f53c-f5e6-49fe-dbc6-ef91cc710760"
   },
   "outputs": [],
   "source": [
    "# compute the average latent activation for each digit type\n",
    "\n",
    "# initialize output matrix (latent shape by 10 digits)\n",
    "sourcecode = np.zeros((latent.shape[1],10))\n",
    "\n",
    "\n",
    "# loop over digit categories\n",
    "for i in range(10):\n",
    "\n",
    "  # find all pictures of this category\n",
    "  digidx = np.where(labels==i)\n",
    "\n",
    "  # average the latent layer output\n",
    "  sourcecode[:,i] = torch.mean(latent[digidx,:],axis=1).detach()\n",
    "\n",
    "\n",
    "# let's see what it looks like!\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.plot(sourcecode,'s-')\n",
    "plt.legend(range(10),loc=(1.01,.4))\n",
    "plt.xticks(range(15))\n",
    "plt.xlabel('Latent node number')\n",
    "plt.ylabel('Activation')\n",
    "plt.title(\"The model's internal representation of the numbers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RumWkrM82B8N"
   },
   "source": [
    "# Explore the reduced-compressed space with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.787678Z",
     "start_time": "2022-01-31T17:12:13.787678Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "mRrEQMXgrCQj",
    "outputId": "c29633b4-baee-49c4-ea57-5e7db0d21adc"
   },
   "outputs": [],
   "source": [
    "# compute and fit the PCA\n",
    "pcaData = PCA(n_components=15).fit(data) # 15 components to match latent, but it's just to speed computation time\n",
    "pcaCode = PCA(               ).fit(latent.detach())\n",
    "\n",
    "\n",
    "# plot the eigenspectra (scree plot)\n",
    "plt.plot(100*pcaData.explained_variance_ratio_,'s-',label='Data PCA')\n",
    "plt.plot(100*pcaCode.explained_variance_ratio_,'o-',label='Code PCA')\n",
    "plt.xlabel('Components')\n",
    "plt.ylabel('Percent variance explained')\n",
    "plt.title('PCA scree plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.788673Z",
     "start_time": "2022-01-31T17:12:13.788673Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "9cAVDrS5vbWC",
    "outputId": "8c57a16d-2aaf-4246-9dab-cd85c1822c1a"
   },
   "outputs": [],
   "source": [
    "# compute the projection of the data onto the PC axes\n",
    "scoresData = pcaData.fit_transform(data)\n",
    "scoresCode = pcaCode.fit_transform(latent.detach())\n",
    "\n",
    "# plot the data separately per number\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "for lab in range(10):\n",
    "  ax[0].plot(scoresData[labels==lab,0],scoresData[labels==lab,1],'o',markersize=3,alpha=.4)\n",
    "  ax[1].plot(scoresCode[labels==lab,0],scoresCode[labels==lab,1],'o',markersize=3,alpha=.4)\n",
    "\n",
    "for i in range(2):\n",
    "  ax[i].set_xlabel('PC1 projection')\n",
    "  ax[i].set_ylabel('PC2 projection')\n",
    "  ax[i].legend(range(10))\n",
    "\n",
    "ax[0].set_title('PCA of data')\n",
    "ax[1].set_title('PCA of latent code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.789672Z",
     "start_time": "2022-01-31T17:12:13.789672Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3vB1b_MGBlVv",
    "outputId": "c0e27ecc-0a7f-4d10-828d-a8c69bb2e5e9"
   },
   "outputs": [],
   "source": [
    "# This cell is not important! It's just the code I used to make the figure in the slide. I decided to leave it here FYI.\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(15,3))\n",
    "\n",
    "ax[0].imshow(dataT[0,:].view(28,28),cmap='gray')\n",
    "\n",
    "ax[1].plot(dataT[0,:],'ks')\n",
    "ax[1].set_xlabel('Pixels (vectorized)')\n",
    "ax[1].set_ylabel('Intensity value')\n",
    "\n",
    "ax[2].plot(latent[0,:].detach(),'ks')\n",
    "ax[2].set_xlabel('Latent units')\n",
    "ax[2].set_ylabel('Activation (a.u.)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlmKG35AVGJp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uh28k_l29urR"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T17:12:13.790669Z",
     "start_time": "2022-01-31T17:12:13.790669Z"
    },
    "id": "ib3uQtfv9wE2"
   },
   "outputs": [],
   "source": [
    "# 1) Are you surprised that the latent activations (e.g., from the histogram) are all non-negative? Is that because of \n",
    "#    the image normalization, or what is causing those values to be all non-negative?\n",
    "# \n",
    "# 2) Averages don't tell the whole story. Redraw the \"Model's internal representation\" line plot but using standard \n",
    "#    deviation instead of mean. This graph will tell you if any numbers, or units, have particularly higher variability\n",
    "#    than others. Is this the case, and does the std plot give you any more insight into the model's learned representation?\n",
    "# \n",
    "# 3) The PC-space plots are tricky to interpret: This is a 15-dimensional space but 13 dimensions are projected onto two.\n",
    "#    It's possible that the numbers are better separated in other dimensions, just like a 2D photograph of someone standing\n",
    "#    behind a tree makes them inseparable whereas they are separable in the original 3D space. Modify the plot to show\n",
    "#    PC dimensions 2&3 instead of 1&2. \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 4 - The latent code of MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
