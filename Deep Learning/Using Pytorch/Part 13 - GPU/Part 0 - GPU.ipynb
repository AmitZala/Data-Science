{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca66b6b3",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "| Central Processing Unit | Graphics Processing Unit |\n",
    "| :-- | :-- |\n",
    "| General purpose | Custom-designed for matrix mult. |\n",
    "| Mostly serial (though fast) | Designed to be parallel |\n",
    "| A few cores (4, 8, 16) | Thousands of cores |\n",
    "| Interactive use | Breaks a big task in tiny pieces |\n",
    "| Built in to the OS | Requires additional softwares |\n",
    "\n",
    "![Image of CPU vs GPU](https://assets-global.website-files.com/5debb9b4f88fbc3f702d579e/5e08f35d7436081481e15d61_e7b08ad97410491586d63028740b90c1.png)\n",
    "\n",
    ">**Why use a GPU for DL:**\n",
    "- Most of DL is tons of really simple but tedious matrix multiplications.\n",
    "- Training large models can become annoyingly to prohibitively time-consuming.\n",
    "- Therefore: Outsource the calculations to the GPU.\n",
    "\n",
    ">**How to use a GPU for DL:**\n",
    "- *On your computer*: Buy a GPU (all computers have a GPU, but you need a separate GPU). Install Nvidia software. Blah blah CS stuff...\n",
    "- *Use google-colab*: Already setup, you just click a menu option! Consider colab-pro. Or AWS or Azure\n",
    "- Use your university/company computer cluster.\n",
    "\n",
    ">**When to use a GPU for DL:**\n",
    "- When you have large or complex models.\n",
    "- Simple models but running many experiments.\n",
    "- But: Transferring data to/from GPU has additional overhead, more code and more hassle.\n",
    "- The speed gains are minimal for small models.\n",
    "\n",
    ">**Transferring data between CPU and GPU:**\n",
    "- Setup everything on the CPU.\n",
    "- Send model and data to GPU.\n",
    "- GPU crunches the numbers.\n",
    "- Transfer output back to CPU.\n",
    "\n",
    ">**Warning about GPU on colab:**\n",
    "- Colab has finite resources and will block access to their GUPs after excessive use.\n",
    "- You'll lose access only for hours to days, so it's not a big deal. But it can be annoying at the wrong time.\n",
    "- Best to use colab's GPU only when the speed gains are substantial.\n",
    "- Consider colab-pro if you want better resources.\n",
    "\n",
    ">**Code:**\n",
    "- Part 1 - Implementation](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2013%20-%20GPU/Part%201%20-%20Implementation.ipynb)\n",
    "- Part 2 - CodeChallenge Run an experiment on the GPU](https://github.com/Sayan-Roy-729/Data-Science/blob/main/Deep%20Learning/Using%20Pytorch/Part%2013%20-%20GPU/Part%202%20-%20CodeChallenge%20Run%20an%20experiment%20on%20the%20GPU.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fa932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
