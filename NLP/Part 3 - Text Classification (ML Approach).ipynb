{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0127f79",
   "metadata": {},
   "source": [
    "# Text Classification (ML Approach)\n",
    "**Video Link: https://youtu.be/Qbd7U9F0QQ8**\n",
    "\n",
    "**Can use APIs of different platforms. One of them is https://nlpcloud.io/home/token**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5f1e8",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c890d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccf1e0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_csv(\"../Datasets/IMDB_50k_Movie_Reviews/IMDB Dataset.csv\")\n",
    "df = temp_df.iloc[:10000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d97d268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74bbb1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5028\n",
       "negative    4972\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa7163c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf8d10ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d95900d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d16d71d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bc4b0",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90397a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic preprocessing\n",
    "# remove tags\n",
    "# lowercase\n",
    "# remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234030f",
   "metadata": {},
   "source": [
    "### Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24672018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), \"\", raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "579d6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b67181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af371674",
   "metadata": {},
   "source": [
    "### Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ed6bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72946fc",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "099860d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production. filming technique...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's family little boy (jake) thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production. filming technique...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically there's family little boy (jake) thi...  negative\n",
       "4  petter mattei's \"love time money\" visually stu...  positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw_list = stopwords.words(\"english\")\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed64bc",
   "metadata": {},
   "source": [
    "## Model Creation & Accuracy Score\n",
    "\n",
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdd93d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       one reviewers mentioned watching 1 oz episode ...\n",
       "1       wonderful little production. filming technique...\n",
       "2       thought wonderful way spend time hot summer we...\n",
       "3       basically there's family little boy (jake) thi...\n",
       "4       petter mattei's \"love time money\" visually stu...\n",
       "                              ...                        \n",
       "9995    fun, entertaining movie wwii german spy (julie...\n",
       "9996    give break. anyone say \"good hockey movie\"? kn...\n",
       "9997    movie bad movie. watching endless series bad h...\n",
       "9998    movie probably made entertain middle school, e...\n",
       "9999    smashing film film-making. shows intense stran...\n",
       "Name: review, Length: 9983, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 0]\n",
    "y = df.iloc[:, -1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4c99421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90528b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd102f34",
   "metadata": {},
   "source": [
    "### Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20915059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appling BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv          = CountVectorizer()\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train[:]).toarray()\n",
    "X_test_bow  = cv.transform(X_test[:]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae8a7e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 48282)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e7e02",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2c6bc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Base Algorithm'\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "250b594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324486730095142"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test_bow)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "839f2f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[717, 235],\n",
       "       [499, 546]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ecb27",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07858cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442663995993991"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf    = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15b09eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522784176264396"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv          = CountVectorizer(max_features = 3000)\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train[:]).toarray()\n",
    "X_test_bow  = cv.transform(X_test[:]).toarray()\n",
    "\n",
    "rf          = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred      = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a0c06",
   "metadata": {},
   "source": [
    "### n-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e47dfad",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 102. GiB for an array with shape (7986, 1711897) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9148/1727915526.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcv\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_test_bow\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 102. GiB for an array with shape (7986, 1711897) and data type int64"
     ]
    }
   ],
   "source": [
    "# using n-grams\n",
    "cv          = CountVectorizer(ngram_range = (1, 3))\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train[:]).toarray()\n",
    "X_test_bow  = cv.transform(X_test[:]).toarray()\n",
    "\n",
    "rf          = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred      = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5af58b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8422633950926389"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv          = CountVectorizer(ngram_range = (1, 3), max_features = 5000)\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train[:]).toarray()\n",
    "X_test_bow  = cv.transform(X_test[:]).toarray()\n",
    "\n",
    "rf          = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred      = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d44539",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e84b86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf         = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train[:]).toarray()\n",
    "X_test_tfidf  = tfidf.transform(X_test[:]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51e59772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8477716574862293"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf     = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred = rf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e7962",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15272437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using word2vec\n",
    "import gensim\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "873889cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = []\n",
    "for document in df[\"review\"]:\n",
    "    raw_sentences = sent_tokenize(document)\n",
    "    for sentence in raw_sentences:\n",
    "        story.append(simple_preprocess(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77b9cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window    = 10,\n",
    "    min_count = 2\n",
    ")\n",
    "\n",
    "model.build_vocab(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1218c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5876447, 6212140)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story, total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c34feda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31845"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c8545d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(document):\n",
    "    # remove out-of-vocavulary words\n",
    "    doc = [word for word in document.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7b4c95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11767457,  0.44197842,  0.15793371,  0.23417264, -0.08648166,\n",
       "       -0.57118315,  0.20673536,  0.9118082 , -0.3956981 , -0.24569878,\n",
       "       -0.29675198, -0.48555282,  0.06393063,  0.12023948,  0.21426222,\n",
       "       -0.13143265,  0.01869917, -0.3801883 , -0.02781098, -0.6802106 ,\n",
       "        0.06089593,  0.2382583 ,  0.09646897, -0.22129515, -0.39432743,\n",
       "       -0.0290477 , -0.28285992,  0.0154872 , -0.3290113 ,  0.03619485,\n",
       "        0.3534463 ,  0.03650456,  0.22277047, -0.27120045, -0.18808062,\n",
       "        0.38151145,  0.07626982, -0.41450965, -0.24805413, -0.73923516,\n",
       "        0.14936532, -0.22309735,  0.04557468, -0.04844937,  0.47880465,\n",
       "       -0.14191924, -0.2135583 , -0.01630191,  0.0761856 ,  0.36759058,\n",
       "        0.04451348, -0.399119  , -0.4148597 , -0.09378606, -0.09493089,\n",
       "        0.2585061 ,  0.14484192,  0.07867185, -0.32646737,  0.0779765 ,\n",
       "        0.0504096 ,  0.1291775 ,  0.02581581, -0.14704275, -0.4253138 ,\n",
       "        0.21399641,  0.05135576,  0.13029383, -0.36542377,  0.2687623 ,\n",
       "       -0.2765414 ,  0.09119344,  0.60999185, -0.08486731,  0.41383022,\n",
       "        0.11997015,  0.02497508, -0.13750269, -0.52882   ,  0.18918191,\n",
       "       -0.34081978,  0.06732538, -0.4517469 ,  0.41251352, -0.22265759,\n",
       "       -0.14567104, -0.12016311,  0.2895385 ,  0.24291533,  0.10463294,\n",
       "        0.35255608,  0.24035504, -0.0262132 ,  0.09365887,  0.6382258 ,\n",
       "        0.32010028,  0.150695  , -0.17532653, -0.05179843, -0.14310536],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector(df[\"review\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ec78dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9983/9983 [04:30<00:00, 36.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "for document in tqdm(df[\"review\"].values):\n",
    "    X.append(document_vector(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e20803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9983, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5926750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11767457,  0.44197842,  0.15793371,  0.23417264, -0.08648166,\n",
       "       -0.57118315,  0.20673536,  0.9118082 , -0.3956981 , -0.24569878,\n",
       "       -0.29675198, -0.48555282,  0.06393063,  0.12023948,  0.21426222,\n",
       "       -0.13143265,  0.01869917, -0.3801883 , -0.02781098, -0.6802106 ,\n",
       "        0.06089593,  0.2382583 ,  0.09646897, -0.22129515, -0.39432743,\n",
       "       -0.0290477 , -0.28285992,  0.0154872 , -0.3290113 ,  0.03619485,\n",
       "        0.3534463 ,  0.03650456,  0.22277047, -0.27120045, -0.18808062,\n",
       "        0.38151145,  0.07626982, -0.41450965, -0.24805413, -0.73923516,\n",
       "        0.14936532, -0.22309735,  0.04557468, -0.04844937,  0.47880465,\n",
       "       -0.14191924, -0.2135583 , -0.01630191,  0.0761856 ,  0.36759058,\n",
       "        0.04451348, -0.399119  , -0.4148597 , -0.09378606, -0.09493089,\n",
       "        0.2585061 ,  0.14484192,  0.07867185, -0.32646737,  0.0779765 ,\n",
       "        0.0504096 ,  0.1291775 ,  0.02581581, -0.14704275, -0.4253138 ,\n",
       "        0.21399641,  0.05135576,  0.13029383, -0.36542377,  0.2687623 ,\n",
       "       -0.2765414 ,  0.09119344,  0.60999185, -0.08486731,  0.41383022,\n",
       "        0.11997015,  0.02497508, -0.13750269, -0.52882   ,  0.18918191,\n",
       "       -0.34081978,  0.06732538, -0.4517469 ,  0.41251352, -0.22265759,\n",
       "       -0.14567104, -0.12016311,  0.2895385 ,  0.24291533,  0.10463294,\n",
       "        0.35255608,  0.24035504, -0.0262132 ,  0.09365887,  0.6382258 ,\n",
       "        0.32010028,  0.150695  , -0.17532653, -0.05179843, -0.14310536],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03a5d025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73ab942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c16a6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.730095142714071"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = GaussianNB()\n",
    "\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mnb.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38396edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7726589884827241"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
